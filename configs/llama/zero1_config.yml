{
  # for all zero_optimization options, see https://www.deepspeed.ai/docs/config-json/#zero-optimizations-for-fp16-training

  "zero_optimization": {
    "stage": 1,
    "allgather_partitions": True,
    "allgather_bucket_size": 500000000,
    "overlap_comm": True,
    "reduce_scatter": True,
    "reduce_bucket_size": 500000000,
    "contiguous_gradients": True,
    "offload_optimizer": { # 없으면 OOM
      "device": "cpu"
    },
  },
  
  "optimizer": {
    # "type": "adam", # no cpu offload
    "type": "cpu_adam", # cpu offload
    "params": {
      "lr": 0.0002,
      "betas": [0.9, 0.95],
      "eps":  1.0e-8,
    }
  },
}